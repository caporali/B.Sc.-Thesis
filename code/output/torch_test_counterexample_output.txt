0. NN structure
- activation: ReLU
- NeuralNetwork(
  (linears): ModuleList(
    (0): Linear(in_features=1, out_features=5, bias=True)
    (1): Linear(in_features=5, out_features=5, bias=True)
    (2): Linear(in_features=5, out_features=5, bias=True)
    (3): Linear(in_features=5, out_features=5, bias=True)
    (4): Linear(in_features=5, out_features=1, bias=False)
  )
) 

1. NN parameters
W_1:
- size: 5x1
- distribution: N(0, 0.16)
- content: 
 [[ 0.  ]
 [-0.37]
 [-0.22]
 [ 0.37]
 [ 0.04]] 
	----
b_1:
- size: 5
- distribution: N(0, 0.2)
- content: 
 [ 0.19 -0.02 -0.26  0.28  0.21] 
	----
W_2:
- size: 5x5
- distribution: N(0, 0.8)
- content: 
 [[ 0.19  0.62  1.62  0.87 -1.43]
 [ 1.41  1.04 -0.82 -0.62 -0.47]
 [ 0.68  0.62  1.09 -0.57 -1.21]
 [ 0.61  0.34  1.09 -1.94 -0.41]
 [-0.67 -0.44  0.49  1.1  -0.94]] 
	----
b_2:
- size: 5
- distribution: N(0, 0.2)
- content: 
 [ 0.58  0.14 -0.34 -1.17 -0.33] 
	----
W_3:
- size: 5x5
- distribution: N(0, 0.16)
- content: 
 [[-0.19 -0.36  0.27  0.56 -0.43]
 [ 0.54 -0.08 -0.31  0.33  0.05]
 [ 0.29 -0.43  0.31  0.34  0.54]
 [ 0.14  0.11 -0.11 -0.27  0.09]
 [ 0.01 -0.22  0.23 -0.09  0.08]] 
	----
b_3:
- size: 5
- distribution: N(0, 0.2)
- content: 
 [0.08 0.69 0.21 0.46 0.15] 
	----
W_4:
- size: 5x5
- distribution: N(0, 0.16)
- content: 
 [[-0.45  0.69 -0.72 -0.3   0.15]
 [ 0.17 -0.36 -0.1  -0.12 -0.53]
 [ 0.28 -0.31  0.63 -0.17  0.27]
 [-0.07  0.34  0.17 -0.03  0.39]
 [-0.28 -0.7  -0.3  -0.59  0.66]] 
	----
b_4:
- size: 5
- distribution: N(0, 0.2)
- content: 
 [-0.16  0.17  0.33  0.47 -0.41] 
	----
W_5:
- size: 1x5
- distribution: N(0, 0.16)
- content: 
 [[ 0.19 -0.18  0.1   0.42 -0.42]] 
	----

2. test:
	- input:  [1.]
	- output: [0.46]
